{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2b77d21-e346-43a9-adab-243a320f360f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "# import gym_snake_game\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc2df30f-85cf-4b71-a550-72cb702de51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make('MountainCar-v0', render_mode='rgb_array')\n",
    "# env = gym.make('CarRacing-v2', render_mode='rgb_array')\n",
    "env = gym.make(\"CartPole-v1\", render_mode='rgb_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "977e28d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rough\n",
    "env.reset()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0d199b2-6d86-4e0c-ace3-b8ec253a0034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "random.shuffle(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f8166d8-c489-44bd-bdef-b4029888d228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_game_video(env, model=None , MAX_DUR=1000):\n",
    "    img_array = []\n",
    "    size = None\n",
    "    env.reset()\n",
    "    img_array.append(env.render())\n",
    "    for i in range(MAX_DUR):\n",
    "        if model == None:\n",
    "            action = env.action_space.sample()\n",
    "        else :\n",
    "            pass\n",
    "        state = env.step(action)[0]\n",
    "        img = env.render()\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        img_array.append(img)\n",
    "    \n",
    "    size = img_array[0].shape\n",
    "    size = size[:2]\n",
    "#     print(img_array[0].dtype)\n",
    "    vid = cv2.VideoWriter('game_vid.avi' , cv2.VideoWriter_fourcc(*'DIVX'), fps=15 ,frameSize=size)\n",
    "    for i in img_array:\n",
    "        vid.write(i)\n",
    "    vid.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a190bc-cffc-44c6-b03c-77bb3d258636",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_game_video(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c71ee4-5c51-4dd5-b1a1-d0b17509109e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(env.reset()[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80987aeb-d915-4bd6-9066-473df5cd59f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    inps = keras.layers.Input(shape=(4))\n",
    "#     x = keras.layers.Flatten()(inp)\n",
    "    x = keras.layers.Dense(200, activation='relu')(inps)\n",
    "#     x = keras.layers.Dense(100, activation='relu')(inps)\n",
    "#     x = keras.layers.Dense(200, activation='relu')(x)\n",
    "#     x = keras.layers.Dense(100, activation='relu')(x)\n",
    "    outs = keras.layers.Dense(2, activation='softmax')(x)\n",
    "    model = keras.Model(inputs=inps , outputs=outs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e9538a-9357-40e7-9633-db77c724aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "s = env.reset()[0]\n",
    "print(s)\n",
    "# s = process_state(s)\n",
    "model(np.array([s]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8731462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.step(np.array(model(np.array([[s,s,s,s]]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd9109db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_reward(rewards, gamma=0.99):\n",
    "    disc_r = tf.pow(gamma, np.arange(len(rewards))) * rewards\n",
    "    r = tf.math.reduce_sum(disc_r)\n",
    "    \n",
    "def process_state(state):\n",
    "    return state\n",
    "    return np.expand_dims(state, axis=0)\n",
    "    \n",
    "def e_greedy(action_prob, e = 0.01):\n",
    "    if random.random()<e:\n",
    "        return random.randint(0,len(action_prob)-1)\n",
    "    else :\n",
    "        return np.argmax(action_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd376d1-26d3-4dc2-b0eb-21558ee31b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLE TRAINING:\n",
    "\n",
    "model = make_model()\n",
    "\n",
    "optim = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "epochs = 100\n",
    "episode_len = 200\n",
    "\n",
    "gamma = 0.9\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    state = env.reset()[0]\n",
    "    state = process_state(state)\n",
    "#     state = np.array(state)\n",
    "    done = False\n",
    "    t = 0\n",
    "    G = 0\n",
    "    losses = []\n",
    "    while t<episode_len and (not done):\n",
    "        print(state)\n",
    "        action_prob = model(np.array([state]))[0]\n",
    "#         print(action_prob)\n",
    "#         action = e_greedy(action_prob)\n",
    "        action = np.random.choice([0,1], p=np.array(action_prob))\n",
    "#         print(action)\n",
    "        prev_state = state\n",
    "        state , reward, done, _ , info = env.step(action)\n",
    "        state = process_state(state)\n",
    "        G += reward*tf.pow(gamma, t)\n",
    "        t+=1\n",
    "        target = tf.Variable(tf.zeros(len(action_prob[0])))\n",
    "#         print(target)\n",
    "        target[action].assign(1)\n",
    "#         print('target : ', target)\n",
    "        with tf.GradientTape() as tape:\n",
    "            action_prob = model(np.array([prev_state]))[0]\n",
    "            loss = tf.reduce_sum(tf.math.log(tf.pow(target-action_prob,2)) / G)\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "#         print(\"loss: \",loss)\n",
    "#         print(\"gradients : \" ,gradients)\n",
    "        losses.append(loss.numpy())\n",
    "        optim.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    loss_history.append(np.sum(losses)/len(losses))\n",
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a23b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(done, t, G)\n",
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac7d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(env.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab647f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()[0]\n",
    "done = False\n",
    "for i in range(500):\n",
    "    action = np.argmax(model(process_state(np.array([state])))[0])\n",
    "    _ = env.step(action)\n",
    "    done = _[2]\n",
    "    if done or _[3]:\n",
    "        break;\n",
    "    state = _[0]\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c1015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(env.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615ab4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gym.wrappers.monitoring.video_recorder import VideoRecorder\n",
    "# import gym\n",
    "# max_time = 200\n",
    "# record_env = RecordVideo(env , './mp4', video_length=max_time)\n",
    "\n",
    "# state = env.reset()[0]\n",
    "# state = process_state(state)\n",
    "# ans = 0\n",
    "# done = False\n",
    "\n",
    "# while ans < max_time and done==False:\n",
    "#     action = np.argmax(model(np.array([state]))[0])\n",
    "#     state , r , done,_ ,__ = record_env.step(action)\n",
    "#     state = process_state(state)\n",
    "#     ans += 1\n",
    "\n",
    "# record_env.close()\n",
    "# print(done)\n",
    "# print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e04f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c19198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_rewards(rewards, gamma=0.99):\n",
    "    lenr = len(rewards)\n",
    "    disc_return = np.power(gamma,np.arange(lenr)) * rewards \n",
    "    disc_return /= disc_return.max() \n",
    "    return disc_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbe56624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 13:45:01.451933: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 13:45:01.477536: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 13:45:01.477899: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 13:45:01.478847: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 13:45:01.479414: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 13:45:01.479765: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 13:45:01.480068: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 13:45:01.917085: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 13:45:01.917253: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 13:45:01.917375: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 13:45:01.917474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1799 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2023-02-27 13:45:02.462653: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x3fc844c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-27 13:45:02.462674: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2023-02-27 13:45:02.472617: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-02-27 13:45:02.549733: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd8d82247c0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TRAINING WITH EXPERIENCE REPLAY:\n",
    "\n",
    "model = make_model()\n",
    "\n",
    "env = gym.make(\"CartPole-v1\", render_mode='rgb_array')\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "\n",
    "\n",
    "epochs = 1\n",
    "episode_len = 200\n",
    "\n",
    "gamma = 0.99\n",
    "loss_history = []\n",
    "e = 0.01\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    state1 = env.reset()[0]\n",
    "    done = False\n",
    "    t = 0\n",
    "    replay = []\n",
    "    if epoch%60 == 0:\n",
    "        e/=10\n",
    "        \n",
    "    for t in range(episode_len):\n",
    "        t+=1\n",
    "        action_prob = model(np.array([state1]))[0]\n",
    "#         print(action_prob)\n",
    "        action = np.random.choice([0,1], p=np.array(action_prob))\n",
    "#         action = e_greedy(action_prob, e)\n",
    "        state2 , r, done , truncated , info = env.step(action)\n",
    "        experience = [state1, action , t+1]\n",
    "        replay.append(experience)\n",
    "        state1 = state2\n",
    "        if done :\n",
    "            break\n",
    "    \n",
    "    action_batch = [a for (s,a,r) in replay]\n",
    "    state_batch = [s for (s,a,r) in replay]\n",
    "    reward_batch = [r for (s,a,r) in replay]\n",
    "    \n",
    "    reward_batch = np.array(reward_batch[::-1])\n",
    "    g = np.power(gamma, np.arange(t))*reward_batch\n",
    "    g = g/np.max(g)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_batch = model(np.array(state_batch),  training=True)\n",
    "        prob_batch = tf.gather_nd(pred_batch , indices=[[i,j] for i,j in enumerate(action_batch)])\n",
    "        loss = -tf.reduce_sum(g * tf.math.log(prob_batch))\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    loss_history.append(t)\n",
    "    \n",
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f042b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_rewards(rewards, gamma=0.99):\n",
    "    lenr = len(rewards)\n",
    "    disc_return = np.power(gamma,np.arange(lenr)) * rewards \n",
    "    disc_return /= disc_return.max() \n",
    "    return disc_return\n",
    "\n",
    "inputs = keras.layers.Input(4)\n",
    "x = keras.layers.Dense(200, activation = 'relu')(inputs)\n",
    "# x = keras.layers.Dense(200 , activation = 'relu')(x)\n",
    "outputs = keras.layers.Dense(2, activation = 'softmax')(x)\n",
    "\n",
    "model = make_model()\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "EPOCHS = 300\n",
    "\n",
    "history = []\n",
    "for play in range(EPOCHS):\n",
    "    MAX_DUR = 200\n",
    "    state1 = env.reset()[0]\n",
    "    transitions = []\n",
    "\n",
    "    for t in range(MAX_DUR):\n",
    "        action_prob = model(np.array([state1]))\n",
    "        action_prob = np.squeeze(action_prob)\n",
    "        action = np.random.choice([0,1], p=action_prob)\n",
    "        _ = env.step(action)\n",
    "        state2 = _[0]\n",
    "        #reward = _[1]\n",
    "        done = _[2]\n",
    "        transitions.append([state1, action, state2, t+1])\n",
    "        if done :\n",
    "            break\n",
    "\n",
    "        state1 = state2\n",
    "    ep_len = len(transitions)\n",
    "    reward_batch = [r for (s1,a,s2,r) in transitions]\n",
    "    reward_batch = np.array(reward_batch[::-1])\n",
    "    state_batch = [s1 for (s1,a,s2,r) in transitions]\n",
    "    state_batch = np.array(state_batch)\n",
    "    action_batch = [a for (s1,a,s2,r) in transitions]\n",
    "    action_batch = np.array(action_batch)\n",
    "    \n",
    "    gamma = 0.99\n",
    "    \n",
    "    reward = discount_rewards(reward_batch)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_batch = model(state_batch,  training=True)\n",
    "        prob_batch = tf.gather_nd(pred_batch , indices=[[i,j] for i,j in enumerate(action_batch)])\n",
    "        loss = -tf.reduce_sum(reward * tf.math.log(prob_batch))\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    history.append(ep_len)\n",
    "\n",
    "#     def loss_fn(preds, r): \n",
    "#         return -1 * np.sum(r * np.log(preds)) \n",
    "    \n",
    "#     def discount_rewards(rewards, gamma=0.99):\n",
    "#         lenr = len(rewards)\n",
    "#         disc_return = np.power(gamma,np.arange(lenr)) * rewards \n",
    "#         disc_return /= disc_return.max() \n",
    "#         return disc_return\n",
    "\n",
    "\n",
    "# history = train_loop(model)\n",
    "plt.plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a097f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = 0\n",
    "z = 0\n",
    "n = 1000\n",
    "for i in range(n):\n",
    "    if np.random.choice([0,1], p=[0.6,0.4]) == 0:\n",
    "        z+=1\n",
    "    else :\n",
    "        o += 1\n",
    "print(z/n,  o/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb635c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f92aca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "efb82b4cf87d3f9b9b01c2d114c1240deefb13e4b0dfd9ebf4d4f9d0c7b998a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
